{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "Zp5p4GzaB1Ci"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('preprocessed_data.csv')"
      ],
      "metadata": {
        "id": "u-BF0TsNB2-e"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vOoGUqzCB5A",
        "outputId": "4f350975-08fd-43d0-d110-023e820909a7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38050 entries, 0 to 38049\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Unnamed: 0    38050 non-null  int64  \n",
            " 1   clean_text    38050 non-null  object \n",
            " 2   category      38050 non-null  float64\n",
            " 3   Length        38050 non-null  float64\n",
            " 4   Preprocessed  38050 non-null  object \n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 1.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "X = df['Preprocessed']\n",
        "y = df['category']"
      ],
      "metadata": {
        "id": "xpKEFyaECEbC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text and train Word2Vec embeddings\n",
        "vector_size = 100\n",
        "window = 5\n",
        "min_count = 1\n",
        "sg = 1  # Skip-gram (use sg=0 for CBOW)"
      ],
      "metadata": {
        "id": "IIZfYiF0GbOD"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts = [text.split() for text in X]\n",
        "word2vec_model = Word2Vec(tokenized_texts, vector_size=vector_size, window=window, min_count=min_count, sg=sg)\n"
      ],
      "metadata": {
        "id": "CsixzMdDGbTp"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create average word embeddings for each text\n",
        "X_embeddings = np.array([\n",
        "    np.mean([word2vec_model.wv[word] for word in text if word in word2vec_model.wv], axis=0)\n",
        "    for text in tokenized_texts\n",
        "])\n"
      ],
      "metadata": {
        "id": "Aqz9LtY7GbWQ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and validation sets\n",
        "X_train_embeddings, X_val_embeddings, y_train, y_val = train_test_split(X_embeddings, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "DfqrH9eXGbYp"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multinomial NB\n",
        "\n",
        "# Fitting Naive Bayes to the Training set\n",
        "\n",
        "clf = Pipeline([\n",
        "    ('Normalizing',MinMaxScaler()),\n",
        "     ('MultinomialNB',MultinomialNB())\n",
        "     ])\n",
        "\n",
        "clf.fit(X_train_embeddings,y_train)\n",
        "\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = clf.predict(X_val_embeddings)"
      ],
      "metadata": {
        "id": "LpIf3e2VwsIs"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_val,y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD1P2SKxxCAj",
        "outputId": "5a5a27fd-2dea-4cee-be82-f439a0736e93"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.00      0.00      0.00      3832\n",
            "         1.0       0.66      1.00      0.80      7583\n",
            "\n",
            "    accuracy                           0.66     11415\n",
            "   macro avg       0.33      0.50      0.40     11415\n",
            "weighted avg       0.44      0.66      0.53     11415\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}