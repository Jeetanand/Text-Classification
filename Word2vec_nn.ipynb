{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "Zp5p4GzaB1Ci"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('preprocessed_data.csv')"
      ],
      "metadata": {
        "id": "u-BF0TsNB2-e"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vOoGUqzCB5A",
        "outputId": "5eb952c5-1d93-4c2b-9002-5ece65468d57"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38050 entries, 0 to 38049\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Unnamed: 0    38050 non-null  int64  \n",
            " 1   clean_text    38050 non-null  object \n",
            " 2   category      38050 non-null  float64\n",
            " 3   Length        38050 non-null  float64\n",
            " 4   Preprocessed  38050 non-null  object \n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 1.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "X = df['Preprocessed']\n",
        "y = df['category']"
      ],
      "metadata": {
        "id": "xpKEFyaECEbC"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text and train Word2Vec embeddings\n",
        "vector_size = 100\n",
        "window = 5\n",
        "min_count = 1\n",
        "sg = 1  # Skip-gram (use sg=0 for CBOW)"
      ],
      "metadata": {
        "id": "IIZfYiF0GbOD"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts = [text.split() for text in X]\n",
        "word2vec_model = Word2Vec(tokenized_texts, vector_size=vector_size, window=window, min_count=min_count, sg=sg)\n"
      ],
      "metadata": {
        "id": "CsixzMdDGbTp"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create average word embeddings for each text\n",
        "X_embeddings = np.array([\n",
        "    np.mean([word2vec_model.wv[word] for word in text if word in word2vec_model.wv], axis=0)\n",
        "    for text in tokenized_texts\n",
        "])\n"
      ],
      "metadata": {
        "id": "Aqz9LtY7GbWQ"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and validation sets\n",
        "X_train_embeddings, X_val_embeddings, y_train, y_val = train_test_split(X_embeddings, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "DfqrH9eXGbYp"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsIK8GvGP9mc",
        "outputId": "f7079f9b-645c-442f-e178-85b147f75b11"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30440, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFONC3n3QP6b",
        "outputId": "26ad84ad-484f-44ef-de61-c8e899736ad1"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7610, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your original labels are stored in the 'y_train' and 'y_val' variables\n",
        "y_train = np.where(y_train == -1, 0, y_train)  # Convert -1 to 0\n",
        "y_val = np.where(y_val == -1, 0, y_val)  # Convert -1 to 0\n"
      ],
      "metadata": {
        "id": "iN3LrXtyTryJ"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sentiment analysis model\n",
        "def create_sentiment_model(input_shape, num_classes):\n",
        "    input_layer = Input(shape=input_shape, dtype='float32', name='input_embeddings')\n",
        "    dense_layer = Dense(128, activation='relu')(input_layer)  # Adjust units as needed\n",
        "    output_layer = Dense(num_classes, activation='softmax')(dense_layer)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='sentiment_model')\n",
        "    return model"
      ],
      "metadata": {
        "id": "c6SuposaGpLz"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2  # Binary sentiment classification\n",
        "sentiment_model = create_sentiment_model(input_shape=(X_train_embeddings.shape[1],), num_classes=num_classes)\n",
        "sentiment_model.compile(optimizer=Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "T_qCCdvkGslF"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "num_epochs = 10\n",
        "batch_size = 16\n",
        "\n",
        "history = sentiment_model.fit(\n",
        "    X_train_embeddings, y_train,\n",
        "    validation_data=(X_val_embeddings, y_val),\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I-_Doh7Gwbz",
        "outputId": "8a2a8b84-5627-4c00-dd34-7f98096fe6e4"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1903/1903 [==============================] - 54s 28ms/step - loss: 0.5636 - accuracy: 0.6939 - val_loss: 0.5463 - val_accuracy: 0.7087\n",
            "Epoch 2/10\n",
            "1903/1903 [==============================] - 5s 3ms/step - loss: 0.5409 - accuracy: 0.7138 - val_loss: 0.5382 - val_accuracy: 0.7185\n",
            "Epoch 3/10\n",
            "1903/1903 [==============================] - 5s 3ms/step - loss: 0.5320 - accuracy: 0.7198 - val_loss: 0.5322 - val_accuracy: 0.7252\n",
            "Epoch 4/10\n",
            "1903/1903 [==============================] - 4s 2ms/step - loss: 0.5260 - accuracy: 0.7256 - val_loss: 0.5234 - val_accuracy: 0.7264\n",
            "Epoch 5/10\n",
            "1903/1903 [==============================] - 4s 2ms/step - loss: 0.5203 - accuracy: 0.7284 - val_loss: 0.5203 - val_accuracy: 0.7298\n",
            "Epoch 6/10\n",
            "1903/1903 [==============================] - 6s 3ms/step - loss: 0.5139 - accuracy: 0.7333 - val_loss: 0.5228 - val_accuracy: 0.7271\n",
            "Epoch 7/10\n",
            "1903/1903 [==============================] - 4s 2ms/step - loss: 0.5094 - accuracy: 0.7376 - val_loss: 0.5176 - val_accuracy: 0.7331\n",
            "Epoch 8/10\n",
            "1903/1903 [==============================] - 4s 2ms/step - loss: 0.5072 - accuracy: 0.7380 - val_loss: 0.5392 - val_accuracy: 0.7221\n",
            "Epoch 9/10\n",
            "1903/1903 [==============================] - 5s 3ms/step - loss: 0.5027 - accuracy: 0.7415 - val_loss: 0.5096 - val_accuracy: 0.7363\n",
            "Epoch 10/10\n",
            "1903/1903 [==============================] - 5s 3ms/step - loss: 0.4997 - accuracy: 0.7417 - val_loss: 0.5245 - val_accuracy: 0.7240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "y_pred = sentiment_model.predict(X_val_embeddings)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_val, y_pred_labels)\n",
        "print(f'Validation Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewe4qcBpG65G",
        "outputId": "e77a2805-e073-4d4b-f94f-888057c48b18"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238/238 [==============================] - 0s 1ms/step\n",
            "Validation Accuracy: 0.72\n"
          ]
        }
      ]
    }
  ]
}